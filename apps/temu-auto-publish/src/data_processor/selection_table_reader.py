"""
@PURPOSE: è¯»å–å’Œå¤„ç†Excelé€‰å“è¡¨ï¼Œæå–å•†å“ä¿¡æ¯ç”¨äºé‡‡é›†
@OUTLINE:
  - class SelectionTableReader: é€‰å“è¡¨è¯»å–å™¨
  - def read_excel(): è¯»å–Excel/CSVæ–‡ä»¶
  - def _read_csv(): CSVè¯»å–è¾…åŠ©
  - def validate_row(): éªŒè¯è¡Œæ•°æ®å®Œæ•´æ€?  - def extract_products(): æå–äº§å“åˆ—è¡¨
@GOTCHAS:
  - Excelæ ¼å¼å¿…é¡»ç¬¦åˆSOPè§„èŒƒ
  - å‹å·ç¼–å·æ ¼å¼ä¸ºA0001, A0002ç­?  - å°ºå¯¸å›¾åˆ—éœ€æä¾›å®Œæ•´å¯è®¿é—®çš„ URL, ä¸å†æ”¯æŒæŒ‰å‰ç¼€æ‹¼æ¥
@DEPENDENCIES:
  - å¤–éƒ¨: pandas, openpyxl
  - å†…éƒ¨: loguru
@RELATED: collection_controller.py, collection_workflow.py
@CHANGELOG:
  - 2025-11-01: åˆå§‹åˆ›å»ºï¼Œå®ç°Excelé€‰å“è¡¨è¯»å–åŠŸèƒ?"""

import json
import os
from urllib.parse import urljoin
from pathlib import Path

import pandas as pd
from pandas.errors import ParserError
from loguru import logger
from pydantic import BaseModel, Field, field_validator


class ProductSelectionRow(BaseModel):
    """é€‰å“è¡¨ä¸­çš„å•è¡Œäº§å“æ•°æ?

    æ ¹æ®SOPæ–‡æ¡£å®šä¹‰çš„Excelç»“æ„ï¼?    - ä¸»å“è´Ÿè´£äº?    - äº§å“åç§° (ç”¨ä½œæœç´¢å…³é”®è¯?
    - æ ‡é¢˜åç¼€ (å‹å·ç¼–å·å¦‚A0001)
    - äº§å“é¢œè‰²/è§„æ ¼
    - äº§å“å›?    - å°ºå¯¸å›?
    Attributes:
        owner: ä¸»å“è´Ÿè´£äº?        product_name: äº§å“åç§°/å…³é”®è¯?        model_number: å‹å·ç¼–å· (å¦‚A0001, A026, A045/A046ç­?
        color_spec: äº§å“é¢œè‰²/è§„æ ¼
        collect_count: éœ€è¦é‡‡é›†çš„æ•°é‡ï¼ˆé»˜è®?ï¼?        cost_price: è¿›è´§ä»?æˆæœ¬ä»?
    Examples:
        >>> row = ProductSelectionRow(
        ...     owner="å¼ ä¸‰",
        ...     product_name="è¯ç®±æ”¶çº³ç›?,
        ...     model_number="A0049",
        ...     color_spec="ç™½è‰²/å¤§å·",
        ...     collect_count=5
        ... )
    """

    owner: str = Field(default="æœªæŒ‡å®?, description="ä¸»å“è´Ÿè´£äº?)
    product_name: str = Field(default="", description="äº§å“åç§°ï¼ˆç”¨ä½œæœç´¢å…³é”®è¯ï¼?)
    model_number: str = Field(default="A0000", description="å‹å·ç¼–å·")
    color_spec: str | None = Field(None, description="äº§å“é¢œè‰²/è§„æ ¼")
    collect_count: int = Field(default=5, ge=1, le=100, description="é‡‡é›†æ•°é‡")

    cost_price: float | None = Field(None, description="è¿›è´§ä»?æˆæœ¬ä»?, ge=0)
    spec_unit: str | None = Field(None, description="è§„æ ¼å•ä½åç§°")
    spec_options: list[str] | None = Field(None, description="è§„æ ¼é€‰é¡¹åˆ—è¡¨")
    variant_costs: list[float] | None = Field(None, description="å¤šè§„æ ¼å¯¹åº”çš„è¿›è´§ä»·åˆ—è¡?)
    image_files: list[str] | None = Field(None, description="å®æ‹å›¾æ•°ç»?)
    size_chart_image_url: str = Field(default="", description="å°ºå¯¸å›¾ç½‘ç»œå›¾ç‰?URL")
    product_video_url: str | None = Field(None, description="äº§å“è§†é¢‘ç½‘ç»œ URL")
    sku_image_urls: list[str] = Field(
        default_factory=list, description="SKU å›¾ç‰‡ URL åˆ—è¡¨ï¼ˆç”¨äºæ›¿æ?SKU å›¾ï¼‰"
    )

    @field_validator("model_number")
    @classmethod
    def validate_model_number(cls, v: str) -> str:
        """éªŒè¯å‹å·ç¼–å·æ ¼å¼ï¼ˆæ”¾å®½éªŒè¯ï¼Œæ”¯æŒ A026, A045/A046 ç­‰æ ¼å¼ï¼‰."""
        if not v:
            return "A0000"
        value = v.strip()
        if not value:
            return "A0000"
        if not value.startswith("A"):
            logger.warning("å‹å·ç¼–å·æœªä»¥Aå¼€å¤´ï¼Œè‡ªåŠ¨è¡¥å…¨: {} -> A{}", value, value)
            return f"A{value}"
        return value


class SelectionTableReader:
    """Excelé€‰å“è¡¨è¯»å–å™¨.

    è´Ÿè´£è¯»å–å’Œè§£æExcelé€‰å“è¡¨ï¼Œæå–å•†å“ä¿¡æ¯ç”¨äºé‡‡é›†æµç¨‹ã€?
    Notes:
        - å°ºç å›¾URLéœ€åœ¨CSVä¸­é€šè¿‡"å°ºç å›?åˆ—æ˜ç¡®æä¾›ï¼Œä¸ä¼šä»å®æ‹å›¾æ•°ç»„è‡ªåŠ¨ç”Ÿæˆ
        - æ”¯æŒçš„å°ºç å›¾åˆ—å: å°ºç å›¾ã€å°ºç å›¾é“¾æ¥ã€å°ºç å›¾URLã€å°ºå¯¸å›¾é“¾æ¥ã€å°ºå¯¸å›¾URL
        - å¦‚æœªæä¾›å°ºç å›¾URLï¼Œè¯¥åŠŸèƒ½å°†è¢«è·³è¿‡

    Examples:
        >>> reader = SelectionTableReader()
        >>> products = reader.read_excel("data/input/selection_table.xlsx")
        >>> print(len(products))
        10
        >>> print(products[0].product_name)
        'è¯ç®±æ”¶çº³ç›?
    """

    def __init__(self):
        """åˆå§‹åŒ–é€‰å“è¡¨è¯»å–å™¨."""
        logger.info("é€‰å“è¡¨è¯»å–å™¨åˆå§‹åŒ?)
        self.product_image_base_url = self._resolve_product_image_base_url()

        # Excelåˆ—åæ˜ å°„ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼?        self.column_mapping = {
            "ä¸»å“è´Ÿè´£äº?: "owner",
            "owner": "owner",
            "è´Ÿè´£äº?: "owner",
            "äº§å“åç§°": "product_name",
            "product_name": "product_name",
            "å•†å“åç§°": "product_name",
            "åç§°": "product_name",
            "æ ‡é¢˜åç¼€": "model_number",
            "model_number": "model_number",
            "å‹å·": "model_number",
            "å‹å·ç¼–å·": "model_number",
            "äº§å“é¢œè‰²/è§„æ ¼": "color_spec",
            "color_spec": "color_spec",
            "é¢œè‰²è§„æ ¼": "color_spec",
            "è§„æ ¼": "color_spec",
            "é‡‡é›†æ•°é‡": "collect_count",
            "collect_count": "collect_count",
            "è§„æ ¼æ•°ç»„": "spec_options",
            "è§„æ ¼å•ä½": "spec_unit",
            # æ–°å¢æ˜ å°„ï¼šè¿›è´§ä»·
            "è¿›è´§ä»?: "cost_price",
            "    è¿›è´§ä»?: "cost_price",  # å¤„ç†å¸¦ç©ºæ ¼çš„åˆ—å
            "æˆæœ¬ä»?: "cost_price",
            "cost_price": "cost_price",
            "ä»·æ ¼": "cost_price",
            # æ–°å¢æ˜ å°„ï¼šå®æ‹å›¾æ•°ç»„
            "å®æ‹å›¾æ•°ç»?: "image_files",
            "skuå®æ‹å›¾æ•°ç»?: "image_files",
            "SKUå®æ‹å›¾æ•°ç»?: "image_files",
            "image_files": "image_files",
            "å°ºå¯¸å›¾é“¾æ?: "size_chart_image_url",
            "å°ºå¯¸å›¾URL": "size_chart_image_url",
            "å°ºç å›?: "size_chart_image_url",
            "å°ºç å›¾é“¾æ?: "size_chart_image_url",
            "å°ºç å›¾URL": "size_chart_image_url",
            "size_chart_url": "size_chart_image_url",
            "size_chart_image_url": "size_chart_image_url",
            "image_url": "size_chart_image_url",
            "è§†é¢‘é“¾æ¥": "product_video_url",
            "è§†é¢‘URL": "product_video_url",
            "video_url": "product_video_url",
            "product_video_url": "product_video_url",
        }

    def read_excel(
        self, file_path: str, sheet_name: str = 0, skip_rows: int = 0
    ) -> list[ProductSelectionRow]:
        """è¯»å–Excel/CSVé€‰å“è¡?

        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
            sheet_name: å·¥ä½œè¡¨åç§°æˆ–ç´¢å¼•ï¼ˆé»˜è®¤ç¬¬ä¸€ä¸ªï¼‰
            skip_rows: è·³è¿‡çš„è¡Œæ•°ï¼ˆå¦‚æœæœ‰æ ‡é¢˜è¡Œï¼?
        Returns:
            äº§å“åˆ—è¡¨

        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ?            ValueError: Excelæ ¼å¼é”™è¯¯

        Examples:
            >>> reader = SelectionTableReader()
            >>> products = reader.read_excel("selection.xlsx")
            >>> len(products) > 0
            True
        """
        path = Path(file_path)
        logger.info(f"è¯»å–é€‰å“è¡? {path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ?        if not path.exists():
            raise FileNotFoundError(f"é€‰å“è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {path}")

        try:
            suffix = path.suffix.lower()
            if suffix == ".csv":
                logger.debug("æ£€æµ‹åˆ°CSVæ–‡ä»¶ï¼Œä½¿ç”¨pd.read_csvè¯»å–")
                df = self._read_csv(path, skip_rows)
            else:
                df = pd.read_excel(
                    path,
                    sheet_name=sheet_name,
                    skiprows=skip_rows,
                    dtype=str,  # å…ˆå…¨éƒ¨è¯»æˆå­—ç¬¦ä¸²ï¼Œåç»­è½¬æ?                )
                logger.info(f"âœ?Excelè¯»å–æˆåŠŸï¼Œå…± {len(df)} è¡Œæ•°æ?)
            logger.debug(f"  åˆ—å: {df.columns.tolist()}")

            # æ ‡å‡†åŒ–åˆ—å?            df = self._normalize_columns(df)

            # è½¬æ¢ä¸ºProductSelectionRowåˆ—è¡¨
            products = self.extract_products(df)

            logger.success(f"âœ?æˆåŠŸè§£æ {len(products)} ä¸ªäº§å“?)

            return products

        except Exception as e:
            logger.error(f"è¯»å–é€‰å“è¡¨å¤±è´? {e}")
            raise

    def _read_csv(self, path: Path, skip_rows: int) -> pd.DataFrame:
        """è¯»å–CSVé€‰å“è¡¨ï¼Œè‡ªåŠ¨å¤„ç†å¸¸è§ç¼–ç ."""
        encoding_candidates = (
            "utf-8-sig",
            "utf-8",
            "utf-16",
            "gbk",
            "gb2312",
            "latin-1",  # æœ€åå…œåº•ï¼Œé¿å…æå‰é”™è¯¯è§£ç ä¸­æ–‡åˆ—å
        )
        last_error: str | None = None

        for encoding in encoding_candidates:
            try:
                df = pd.read_csv(
                    path,
                    skiprows=skip_rows,
                    dtype=str,
                    encoding=encoding,
                )
                logger.info(f"âœ?CSVè¯»å–æˆåŠŸï¼ˆç¼–ç ?{encoding}ï¼‰ï¼Œå…?{len(df)} è¡Œæ•°æ?)
                return df
            except UnicodeDecodeError as exc:
                last_error = str(exc)
                logger.debug(
                    "CSVè¯»å–å°è¯•å¤±è´¥ï¼Œç¼–ç ?%sï¼Œé”™è¯?%sã€‚ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªç¼–ç ã€?,
                    encoding,
                    exc,
                )
            except ParserError as exc:
                last_error = str(exc)
                logger.warning(
                    "CSVè§£æå¼‚å¸¸ï¼Œå°è¯•ä½¿ç”?python engine è·³è¿‡å¼‚å¸¸è¡? %s", exc
                )
                try:
                    df = pd.read_csv(
                        path,
                        skiprows=skip_rows,
                        dtype=str,
                        encoding=encoding,
                        engine="python",
                        on_bad_lines="skip",
                    )
                    logger.info(
                        "CSVè¯»å–æˆåŠŸï¼ˆpython engine, ç¼–ç =%sï¼Œå·²è·³è¿‡å¼‚å¸¸è¡Œï¼‰ï¼Œå…± %s è¡Œæ•°æ?,
                        encoding,
                        len(df),
                    )
                    return df
                except Exception as fallback_exc:
                    last_error = str(fallback_exc)
                    logger.debug(
                        "CSV python engine è¯»å–å¤±è´¥ï¼Œç¼–ç ?%sï¼Œé”™è¯?%sã€‚ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªç¼–ç ã€?,
                        encoding,
                        fallback_exc,
                    )
            except Exception as exc:
                last_error = str(exc)
                logger.debug(
                    "CSVè¯»å–å°è¯•å¤±è´¥ï¼Œç¼–ç ?%sï¼Œé”™è¯?%sã€‚ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªç¼–ç ã€?,
                    encoding,
                    exc,
                )

        # æœ€åå…œåº•ï¼šå®½æ¾è§£ç  + è·³è¿‡åè¡Œ
        try:
            df = pd.read_csv(
                path,
                skiprows=skip_rows,
                dtype=str,
                encoding="utf-8",
                encoding_errors="replace",
                engine="python",
                on_bad_lines="skip",
            )
            logger.warning(
                "CSVè¯»å–è¿›å…¥å®¹é”™æ¨¡å¼ï¼ˆutf-8 replace, è·³è¿‡å¼‚å¸¸è¡Œï¼‰ï¼Œå…± %s è¡Œæ•°æ?,
                len(df),
            )
            return df
        except Exception as exc:
            last_error = str(exc)
            logger.debug("CSVå®¹é”™æ¨¡å¼è¯»å–å¤±è´¥: {}", exc)

        error_message = (
            "CSVæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œæ— æ³•è¯†åˆ«ç¼–ç ã€?
            if last_error is None
            else f"CSVæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œæœ€åé”™è¯? {last_error}"
        )
        raise ValueError(error_message)

    def _normalize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–åˆ—å?

        å°†ä¸­æ–‡åˆ—åæ˜ å°„ä¸ºè‹±æ–‡å­—æ®µåã€?
        Args:
            df: åŸå§‹DataFrame

        Returns:
            æ ‡å‡†åŒ–åçš„DataFrame
        """
        # åˆ›å»ºåˆ—åæ˜ å°„
        rename_dict = {}
        for col in df.columns:
            col_str = str(col).strip()
            if col_str in self.column_mapping:
                rename_dict[col] = self.column_mapping[col_str]

        # é‡å‘½ååˆ—
        if rename_dict:
            df = df.rename(columns=rename_dict)
            logger.debug(f"åˆ—åæ ‡å‡†åŒ? {rename_dict}")

        return df

    def extract_products(self, df: pd.DataFrame) -> list[ProductSelectionRow]:
        """ä»DataFrameæå–äº§å“åˆ—è¡¨.

        Args:
            df: pandas DataFrame

        Returns:
            äº§å“åˆ—è¡¨

        Raises:
            ValueError: æ•°æ®éªŒè¯å¤±è´¥
        """
        products = []
        errors = []

        for idx, row in df.iterrows():
            try:
                # è·³è¿‡ç©ºè¡Œ
                if pd.isna(row.get("product_name")) or str(row.get("product_name")).strip() == "":
                    logger.debug(f"è·³è¿‡ç¬?{idx + 1} è¡Œï¼ˆç©ºè¡Œï¼?)
                    continue

                # æ„å»ºäº§å“æ•°æ®
                product_data = {
                    "owner": str(row.get("owner", "æœªæŒ‡å®?)).strip(),
                    "product_name": str(row.get("product_name")).strip(),
                    "model_number": str(row.get("model_number")).strip(),
                    "color_spec": str(row.get("color_spec", "")).strip() or None,
                    "collect_count": self._parse_collect_count(row.get("collect_count")),
                }

                cost_price, variant_costs = self._parse_costs(row.get("cost_price"))
                product_data["cost_price"] = cost_price
                product_data["variant_costs"] = variant_costs
                product_data["spec_options"] = self._parse_json_list(row.get("spec_options"))
                product_data["spec_unit"] = self._parse_scalar(row.get("spec_unit"))
                product_data["image_files"] = self._parse_json_list(row.get("image_files"))
                product_data["sku_image_urls"] = self._build_product_image_urls(
                    product_data["image_files"]
                )
                size_chart_url = self._parse_scalar(row.get("size_chart_image_url"))
                if not size_chart_url:
                    logger.warning(
                        "ç¼ºå°‘å°ºå¯¸å›¾URL(size_chart_image_url)ï¼Œå°†ä½¿ç”¨ç©ºå­—ç¬¦ä¸² (è¡?%s)", idx + 1
                    )
                product_data["size_chart_image_url"] = size_chart_url or ""
                product_data["product_video_url"] = row.get("product_video_url")

                # éªŒè¯å¹¶åˆ›å»ºProductSelectionRow
                product = ProductSelectionRow(**product_data)
                products.append(product)

                logger.debug(f"âœ?ç¬?{idx + 1} è¡? {product.product_name} ({product.model_number})")

            except Exception as e:
                error_msg = f"ç¬?{idx + 1} è¡Œæ•°æ®é”™è¯? {e}"
                errors.append(error_msg)
                logger.warning(f"âš ï¸ {error_msg}")
                continue

        # å¦‚æœæœ‰é”™è¯¯ï¼Œæ±‡æ€»æŠ¥å‘?        if errors:
            logger.warning(f"âš ï¸ å…?{len(errors)} è¡Œæ•°æ®å­˜åœ¨é—®é¢?)
            for err in errors[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯?                logger.warning(f"  - {err}")
            if len(errors) > 5:
                logger.warning(f"  ... è¿˜æœ‰ {len(errors) - 5} ä¸ªé”™è¯?)

        return products

    @staticmethod
    def _parse_collect_count(value: object) -> int:
        if value is None or (isinstance(value, float) and pd.isna(value)):
            return 5
        try:
            return int(float(str(value)))
        except (TypeError, ValueError):
            return 5

    @staticmethod
    def _parse_scalar(value: object) -> str | None:
        if value is None or (isinstance(value, float) and pd.isna(value)):
            return None
        text = str(value).strip()
        return text or None

    @staticmethod
    def _parse_json_list(value: object) -> list[str] | None:
        if value is None or (isinstance(value, float) and pd.isna(value)):
            return None
        if isinstance(value, list):
            return [str(item).strip() for item in value if str(item).strip()]
        text = str(value).strip()
        if not text:
            return None
        try:
            parsed = json.loads(text)
            if isinstance(parsed, list):
                return [str(item).strip() for item in parsed if str(item).strip()]
        except json.JSONDecodeError:
            parts = [item.strip() for item in text.split(",") if item.strip()]
            return parts or None
        return None

    @staticmethod
    def _parse_costs(value: object) -> tuple[float | None, list[float] | None]:
        if value is None or (isinstance(value, float) and pd.isna(value)):
            return None, None
        text = str(value).strip()
        if not text:
            return None, None

        if text.startswith("["):
            try:
                parsed = json.loads(text)
                if isinstance(parsed, list):
                    floats: list[float] = []
                    for item in parsed:
                        try:
                            floats.append(float(item))
                        except (TypeError, ValueError):
                            continue
                    if floats:
                        return floats[0], floats
                    return None, None
            except json.JSONDecodeError:
                return None, None

        try:
            return float(text), None
        except (TypeError, ValueError):
            return None, None

    def validate_row(self, row: dict) -> tuple[bool, str | None]:
        """éªŒè¯å•è¡Œæ•°æ®.

        Args:
            row: è¡Œæ•°æ®å­—å…?
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)

        Examples:
            >>> reader = SelectionTableReader()
            >>> valid, error = reader.validate_row({
            ...     "product_name": "è¯ç®±",
            ...     "model_number": "A0001"
            ... })
            >>> valid
            True
        """
        # æ£€æŸ¥å¿…å¡«å­—æ®?        if not row.get("product_name"):
            return False, "ç¼ºå°‘äº§å“åç§°"

        if not row.get("model_number"):
            return False, "ç¼ºå°‘å‹å·ç¼–å·"

        # éªŒè¯å‹å·æ ¼å¼
        model = str(row.get("model_number")).strip()
        if not (model.startswith("A") and len(model) == 5 and model[1:].isdigit()):
            return False, f"å‹å·ç¼–å·æ ¼å¼é”™è¯¯: {model}ï¼Œåº”ä¸ºA0001-A9999"

        # å°ºç å›¾URLç°åœ¨æ˜¯å¯é€‰çš„ï¼Œä¸å†ä»å®æ‹å›¾æ•°ç»„ç”Ÿæˆ?        # å¦‚æœCSVä¸­æä¾›äº†å°ºç å›¾åˆ—åˆ™ä½¿ç”¨ï¼Œå¦åˆ™è·³è¿‡å°ºç å›¾ä¸Šä¼?        return True, None

    def create_sample_excel(self, output_path: str, num_samples: int = 3) -> None:
        """åˆ›å»ºç¤ºä¾‹Excelé€‰å“è¡?

        ç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºã€?
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            num_samples: ç¤ºä¾‹æ•°é‡

        Examples:
            >>> reader = SelectionTableReader()
            >>> reader.create_sample_excel("data/sample.xlsx", num_samples=3)
        """
        logger.info(f"åˆ›å»ºç¤ºä¾‹é€‰å“è¡? {output_path}")

        # ç¤ºä¾‹æ•°æ®
        sample_data = [
            {
                "ä¸»å“è´Ÿè´£äº?: "å¼ ä¸‰",
                "äº§å“åç§°": "è¯ç®±æ”¶çº³ç›?,
                "æ ‡é¢˜åç¼€": "A0049",
                "äº§å“é¢œè‰²/è§„æ ¼": "ç™½è‰²/å¤§å·",
                "é‡‡é›†æ•°é‡": 5,
                "å°ºå¯¸å›¾é“¾æ?: "https://example.com/images/sample-size-chart-1.jpg",
            },
            {
                "ä¸»å“è´Ÿè´£äº?: "æå››",
                "äº§å“åç§°": "æ™ºèƒ½æ‰‹è¡¨è¿åŠ¨é˜²æ°´",
                "æ ‡é¢˜åç¼€": "A0050",
                "äº§å“é¢œè‰²/è§„æ ¼": "é»‘è‰²/æ ‡å‡†ç‰?,
                "é‡‡é›†æ•°é‡": 5,
                "å°ºå¯¸å›¾é“¾æ?: "https://example.com/images/sample-size-chart-2.jpg",
            },
            {
                "ä¸»å“è´Ÿè´£äº?: "ç‹äº”",
                "äº§å“åç§°": "ä¾¿æºæ´—è¡£æœºè¿·ä½?,
                "æ ‡é¢˜åç¼€": "A0051",
                "äº§å“é¢œè‰²/è§„æ ¼": "è“è‰²/å®¶ç”¨æ¬?,
                "é‡‡é›†æ•°é‡": 5,
                "å°ºå¯¸å›¾é“¾æ?: "https://example.com/images/sample-size-chart-3.jpg",
            },
        ]

        # å–å‰Nä¸?        data = sample_data[:num_samples]

        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜Excel
        df.to_excel(output_path, index=False, engine="openpyxl")

        logger.success(f"âœ?ç¤ºä¾‹é€‰å“è¡¨å·²åˆ›å»º: {output_path}")
        logger.info(f"  åŒ…å« {len(data)} ä¸ªç¤ºä¾‹äº§å“?)

    def _resolve_product_image_base_url(self) -> str | None:
        """è§£æ SKU/å®æ‹å›¾å¤–é“¾åŸºç¡€ URL å‰ç¼€."""

        base_url = os.getenv("PRODUCT_IMAGE_BASE_URL", "")
        text = str(base_url).strip()
        return text or None

    def _build_product_image_urls(self, image_files: list[str] | None) -> list[str]:
        """æ ¹æ®å®æ‹å›¾æ–‡ä»¶åæ„å»º SKU å›¾ç‰‡ URL åˆ—è¡¨."""

        if not image_files:
            return []

        urls: list[str] = []
        for item in image_files:
            text = (item or "").strip()
            if not text:
                continue
            if text.startswith(("http://", "https://")):
                urls.append(text)
            elif self.product_image_base_url:
                url = urljoin(f"{self.product_image_base_url.rstrip('/')}/", text.lstrip("/"))
                urls.append(url)
        return urls



