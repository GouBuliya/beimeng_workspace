"""
@PURPOSE: æ ¼å¼åŒ–åŸå§‹é€‰å“è¡¨Excelæ–‡ä»¶ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
@OUTLINE:
  - def parse_complex_excel(): è§£æå¤æ‚çš„å¤šè¡Œæ ¼å¼Excel
  - def convert_to_standard_format(): è½¬æ¢ä¸ºæ ‡å‡†é€‰å“è¡¨æ ¼å¼
  - def main(): ä¸»å‡½æ•°
@GOTCHAS:
  - åŸå§‹Excelä¸­ä¸€ä¸ªäº§å“å¯èƒ½å å¤šè¡Œï¼ˆä¸»è¡Œ+è§„æ ¼è¡Œï¼‰
  - éœ€è¦å‘ä¸‹å¡«å……äº§å“åç§°å’Œæ ‡é¢˜åç¼€
  - è§„æ ¼ä¿¡æ¯éœ€è¦åˆå¹¶
@DEPENDENCIES:
  - å¤–éƒ¨: pandas, openpyxl
"""

import argparse
import sys
from pathlib import Path
from typing import List, Dict

import pandas as pd
from loguru import logger


def parse_complex_excel(input_file: str) -> pd.DataFrame:
    """è§£æå¤æ‚æ ¼å¼çš„Excelæ–‡ä»¶.
    
    å¤„ç†ä»¥ä¸‹æ ¼å¼ï¼š
    - äº§å“åç§°åœ¨ç¬¬ä¸€è¡Œï¼Œåç»­è¡Œä¸ºç©º
    - æ ‡é¢˜åç¼€å¯èƒ½åœ¨ç¬¬ä¸€è¡Œæˆ–åç»­è¡Œ
    - è§„æ ¼åˆ†å¸ƒåœ¨å¤šè¡Œ
    
    Args:
        input_file: è¾“å…¥Excelæ–‡ä»¶è·¯å¾„
        
    Returns:
        è§£æåçš„DataFrame
    """
    logger.info(f"è¯»å–Excelæ–‡ä»¶: {input_file}")
    
    # è¯»å–æ‰€æœ‰æ•°æ®
    df = pd.read_excel(input_file)
    
    logger.info(f"âœ“ è¯»å–æˆåŠŸï¼Œå…± {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")
    logger.debug(f"åˆ—å: {df.columns.tolist()}")
    
    return df


def convert_to_standard_format(df: pd.DataFrame) -> pd.DataFrame:
    """è½¬æ¢ä¸ºæ ‡å‡†é€‰å“è¡¨æ ¼å¼.
    
    æ ‡å‡†æ ¼å¼è¦æ±‚ï¼š
    - ä¸»å“è´Ÿè´£äºº
    - äº§å“åç§°
    - æ ‡é¢˜åç¼€
    - äº§å“é¢œè‰²/è§„æ ¼
    - é‡‡é›†æ•°é‡
    
    Args:
        df: åŸå§‹DataFrame
        
    Returns:
        æ ‡å‡†æ ¼å¼çš„DataFrame
    """
    logger.info("å¼€å§‹è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼...")
    
    # æå–å…³é”®åˆ—
    key_columns = {
        'åˆ°è´§æƒ…å†µ': 'åˆ°è´§æƒ…å†µ',
        'äº§å“åç§°': 'äº§å“åç§°',
        'æ ‡é¢˜åç¼€': 'æ ‡é¢˜åç¼€',
        'äº§å“é¢œè‰²/è§„æ ¼': 'äº§å“é¢œè‰²/è§„æ ¼',
        '    è¿›è´§ä»·': 'è¿›è´§ä»·',
    }
    
    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    missing_cols = [col for col in key_columns.keys() if col not in df.columns]
    if missing_cols:
        logger.warning(f"ç¼ºå¤±åˆ—: {missing_cols}")
    
    # åˆ›å»ºå·¥ä½œå‰¯æœ¬
    work_df = df[list(key_columns.keys())].copy()
    work_df.columns = list(key_columns.values())
    
    # å‘ä¸‹å¡«å……äº§å“åç§°å’Œæ ‡é¢˜åç¼€
    logger.info("å‘ä¸‹å¡«å……äº§å“åç§°å’Œæ ‡é¢˜åç¼€...")
    work_df['äº§å“åç§°'] = work_df['äº§å“åç§°'].ffill()
    work_df['æ ‡é¢˜åç¼€'] = work_df['æ ‡é¢˜åç¼€'].ffill()
    
    # è¿‡æ»¤æ‰æ— æ•ˆè¡Œï¼ˆæ²¡æœ‰è§„æ ¼ä¿¡æ¯çš„ï¼‰
    logger.info("è¿‡æ»¤æ— æ•ˆè¡Œ...")
    work_df = work_df[work_df['äº§å“é¢œè‰²/è§„æ ¼'].notna()].copy()
    
    # æ·»åŠ é‡‡é›†æ•°é‡ï¼ˆé»˜è®¤5ä¸ªï¼‰
    work_df['é‡‡é›†æ•°é‡'] = 5
    
    # æ·»åŠ è´Ÿè´£äººï¼ˆé»˜è®¤ä¸ºç©ºï¼Œéœ€è¦æ‰‹åŠ¨å¡«å†™ï¼‰
    work_df['ä¸»å“è´Ÿè´£äºº'] = ''
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåº
    standard_df = work_df[[
        'ä¸»å“è´Ÿè´£äºº',
        'äº§å“åç§°',
        'æ ‡é¢˜åç¼€',
        'äº§å“é¢œè‰²/è§„æ ¼',
        'é‡‡é›†æ•°é‡'
    ]].copy()
    
    # æ¸…ç†æ•°æ®
    logger.info("æ¸…ç†æ•°æ®...")
    standard_df = standard_df.dropna(subset=['äº§å“åç§°', 'æ ‡é¢˜åç¼€'])
    
    logger.success(f"âœ“ è½¬æ¢å®Œæˆï¼Œå…± {len(standard_df)} æ¡æœ‰æ•ˆæ•°æ®")
    
    return standard_df


def validate_output(df: pd.DataFrame) -> bool:
    """éªŒè¯è¾“å‡ºæ•°æ®çš„æœ‰æ•ˆæ€§.
    
    Args:
        df: å¾…éªŒè¯çš„DataFrame
        
    Returns:
        æ˜¯å¦é€šè¿‡éªŒè¯
    """
    logger.info("éªŒè¯è¾“å‡ºæ•°æ®...")
    
    issues = []
    
    # æ£€æŸ¥å¿…å¡«åˆ—
    required_cols = ['ä¸»å“è´Ÿè´£äºº', 'äº§å“åç§°', 'æ ‡é¢˜åç¼€', 'äº§å“é¢œè‰²/è§„æ ¼', 'é‡‡é›†æ•°é‡']
    for col in required_cols:
        if col not in df.columns:
            issues.append(f"ç¼ºå°‘å¿…å¡«åˆ—: {col}")
    
    # æ£€æŸ¥ç©ºå€¼
    for col in ['äº§å“åç§°', 'æ ‡é¢˜åç¼€', 'äº§å“é¢œè‰²/è§„æ ¼']:
        null_count = df[col].isna().sum()
        if null_count > 0:
            issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")
    
    # æ£€æŸ¥é‡‡é›†æ•°é‡
    if 'é‡‡é›†æ•°é‡' in df.columns:
        invalid_counts = df[~df['é‡‡é›†æ•°é‡'].between(1, 100)]
        if len(invalid_counts) > 0:
            issues.append(f"æœ‰ {len(invalid_counts)} è¡Œçš„é‡‡é›†æ•°é‡ä¸åœ¨1-100èŒƒå›´å†…")
    
    if issues:
        logger.warning("âš ï¸  å‘ç°ä»¥ä¸‹é—®é¢˜:")
        for issue in issues:
            logger.warning(f"  - {issue}")
        return False
    
    logger.success("âœ“ æ•°æ®éªŒè¯é€šè¿‡")
    return True


def show_preview(df: pd.DataFrame, n: int = 10):
    """æ˜¾ç¤ºæ•°æ®é¢„è§ˆ.
    
    Args:
        df: DataFrame
        n: æ˜¾ç¤ºè¡Œæ•°
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰{n}è¡Œï¼‰")
    logger.info(f"{'='*80}")
    print(df.head(n).to_string(index=False))
    
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡")
    logger.info(f"{'='*80}")
    logger.info(f"æ€»è¡Œæ•°: {len(df)}")
    logger.info(f"äº§å“æ•°: {df['äº§å“åç§°'].nunique()}")
    logger.info(f"è§„æ ¼æ•°: {len(df)}")
    logger.info(f"\näº§å“åˆ—è¡¨ï¼ˆå‰10ä¸ªï¼‰:")
    for i, prod in enumerate(df['äº§å“åç§°'].unique()[:10], 1):
        count = len(df[df['äº§å“åç§°'] == prod])
        logger.info(f"  {i}. {prod} ({count}ä¸ªè§„æ ¼)")


def main():
    """ä¸»å‡½æ•°."""
    parser = argparse.ArgumentParser(
        description="æ ¼å¼åŒ–10æœˆå“Excelé€‰å“è¡¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•
  python format_selection_table.py ../../10æœˆå“.xlsx
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python format_selection_table.py ../../10æœˆå“.xlsx -o selection_formatted.xlsx
  
  # åªé¢„è§ˆä¸ä¿å­˜
  python format_selection_table.py ../../10æœˆå“.xlsx --preview-only
        """
    )
    
    parser.add_argument(
        'input_file',
        help='è¾“å…¥Excelæ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-o', '--output',
        default='selection_formatted.xlsx',
        help='è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤: selection_formatted.xlsxï¼‰'
    )
    
    parser.add_argument(
        '--preview-only',
        action='store_true',
        help='åªé¢„è§ˆæ•°æ®ï¼Œä¸ä¿å­˜æ–‡ä»¶'
    )
    
    parser.add_argument(
        '--preview-lines',
        type=int,
        default=10,
        help='é¢„è§ˆè¡Œæ•°ï¼ˆé»˜è®¤: 10ï¼‰'
    )
    
    args = parser.parse_args()
    
    try:
        # è§£æExcel
        df = parse_complex_excel(args.input_file)
        
        # è½¬æ¢æ ¼å¼
        standard_df = convert_to_standard_format(df)
        
        # éªŒè¯
        validate_output(standard_df)
        
        # é¢„è§ˆ
        show_preview(standard_df, args.preview_lines)
        
        # ä¿å­˜
        if not args.preview_only:
            output_path = Path(args.output)
            if not output_path.is_absolute():
                # ä¿å­˜åˆ°data/inputç›®å½•
                output_path = Path(__file__).parent.parent / 'data' / 'input' / output_path
            
            output_path.parent.mkdir(parents=True, exist_ok=True)
            standard_df.to_excel(output_path, index=False)
            
            logger.success(f"\nâœ… æ–‡ä»¶å·²ä¿å­˜: {output_path}")
            logger.info(f"   æ€»è¡Œæ•°: {len(standard_df)}")
            logger.info(f"   äº§å“æ•°: {standard_df['äº§å“åç§°'].nunique()}")
            logger.info(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
            logger.info(f"   python run_collection_to_edit_test.py --selection {output_path}")
        else:
            logger.info("\nâ­ï¸  é¢„è§ˆæ¨¡å¼ï¼šæœªä¿å­˜æ–‡ä»¶")
    
    except FileNotFoundError:
        logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
        logger.exception("è¯¦ç»†é”™è¯¯:")
        sys.exit(1)


if __name__ == "__main__":
    main()

