"""
@PURPOSE: CLI ç›‘æ§å‘½ä»¤ - æŸ¥çœ‹æŒ‡æ ‡å’Œç”ŸæˆæŠ¥å‘Š
@OUTLINE:
  - monitor_app: Typer ç›‘æ§å‘½ä»¤ç»„
  - stats(): æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
  - report(): ç”ŸæˆæŠ¥å‘Š
  - watch(): å®æ—¶ç›‘æ§(TODO)
@DEPENDENCIES:
  - å†…éƒ¨: src.core.performance_tracker
  - å¤–éƒ¨: typer, rich
"""

import json
from datetime import datetime, timedelta
from pathlib import Path

import typer
from config.settings import settings
from loguru import logger
from rich.console import Console
from rich.table import Table

monitor_app = typer.Typer(
    name="monitor",
    help="ç›‘æ§å’ŒæŒ‡æ ‡ç®¡ç†",
)

console = Console()


@monitor_app.command("stats")
def stats(
    last: str | None = typer.Option(None, "--last", help="æ—¶é—´èŒƒå›´(å¦‚: 1h, 24h, 7d)"),
    workflow_id: str | None = typer.Option(None, "--workflow", help="æŒ‡å®šå·¥ä½œæµID"),
):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯.

    Examples:
        temu-auto-publish monitor stats
        temu-auto-publish monitor stats --last 24h
        temu-auto-publish monitor stats --workflow workflow_abc123
    """
    console.print("\n[bold blue]ğŸ“Š æŒ‡æ ‡ç»Ÿè®¡[/bold blue]\n")

    metrics_dir = settings.get_absolute_path(settings.metrics.storage_dir)

    if not metrics_dir.exists():
        console.print("[yellow]âš [/yellow] æš‚æ— æŒ‡æ ‡æ•°æ®")
        return

    # åŠ è½½æŒ‡æ ‡æ–‡ä»¶
    metric_files = sorted(metrics_dir.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)

    if not metric_files:
        console.print("[yellow]âš [/yellow] æš‚æ— æŒ‡æ ‡æ•°æ®")
        return

    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    if last:
        cutoff_time = _parse_time_range(last)
        metric_files = [
            f for f in metric_files if datetime.fromtimestamp(f.stat().st_mtime) >= cutoff_time
        ]

    # è¿‡æ»¤å·¥ä½œæµ
    if workflow_id:
        metric_files = [f for f in metric_files if workflow_id in f.name]

    if not metric_files:
        console.print("[yellow]âš [/yellow] æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æŒ‡æ ‡æ•°æ®")
        return

    # ç»Ÿè®¡æ•°æ®
    total_workflows = len(metric_files)
    total_success = 0
    total_failure = 0
    total_duration = 0.0

    stage_stats = {
        "stage1": {"count": 0, "success": 0, "total_duration": 0.0},
        "stage2": {"count": 0, "success": 0, "total_duration": 0.0},
        "stage3": {"count": 0, "success": 0, "total_duration": 0.0},
    }

    # å¤„ç†æ¯ä¸ªæŒ‡æ ‡æ–‡ä»¶
    for metric_file in metric_files:
        try:
            data = json.loads(metric_file.read_text(encoding="utf-8"))

            # å·¥ä½œæµçŠ¶æ€
            if data.get("status") == "success":
                total_success += 1
            else:
                total_failure += 1

            # æ€»è€—æ—¶
            if data.get("duration"):
                total_duration += data["duration"]

            # é˜¶æ®µç»Ÿè®¡
            for stage_name, stage_data in data.get("stages", {}).items():
                if stage_name in stage_stats:
                    stage_stats[stage_name]["count"] += 1
                    if stage_data.get("success"):
                        stage_stats[stage_name]["success"] += 1
                    if stage_data.get("duration"):
                        stage_stats[stage_name]["total_duration"] += stage_data["duration"]

        except Exception as e:
            logger.warning(f"è¯»å–æŒ‡æ ‡æ–‡ä»¶å¤±è´¥: {e}")

    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    console.print("[bold]æ€»ä½“ç»Ÿè®¡:[/bold]")
    console.print(f"  æ€»å·¥ä½œæµæ•°: {total_workflows}")
    console.print(f"  æˆåŠŸ: {total_success} ({total_success / total_workflows * 100:.1f}%)")
    console.print(f"  å¤±è´¥: {total_failure} ({total_failure / total_workflows * 100:.1f}%)")
    console.print(f"  å¹³å‡è€—æ—¶: {total_duration / total_workflows:.1f}ç§’")

    # æ˜¾ç¤ºé˜¶æ®µç»Ÿè®¡
    console.print("\n[bold]é˜¶æ®µç»Ÿè®¡:[/bold]")

    table = Table(show_header=True, header_style="bold cyan")
    table.add_column("é˜¶æ®µ", style="cyan")
    table.add_column("æ‰§è¡Œæ¬¡æ•°", justify="right")
    table.add_column("æˆåŠŸç‡", justify="right")
    table.add_column("å¹³å‡è€—æ—¶", justify="right")

    for stage_name, stats in stage_stats.items():
        if stats["count"] > 0:
            success_rate = stats["success"] / stats["count"] * 100
            avg_duration = stats["total_duration"] / stats["count"]

            table.add_row(
                stage_name, str(stats["count"]), f"{success_rate:.1f}%", f"{avg_duration:.1f}s"
            )

    console.print(table)
    console.print(f"\næ•°æ®æ¥æº: {len(metric_files)} ä¸ªæŒ‡æ ‡æ–‡ä»¶")


@monitor_app.command("report")
def report(
    output: Path = typer.Option(
        Path("data/reports/report.csv"), "--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„"
    ),
    format: str = typer.Option("csv", "--format", "-f", help="è¾“å‡ºæ ¼å¼(csv/json)"),
    last: str | None = typer.Option(None, "--last", help="æ—¶é—´èŒƒå›´"),
):
    """ç”ŸæˆæŒ‡æ ‡æŠ¥å‘Š.

    Examples:
        temu-auto-publish monitor report
        temu-auto-publish monitor report -o report.json -f json
        temu-auto-publish monitor report --last 7d
    """
    console.print("\n[bold blue]ğŸ“„ ç”ŸæˆæŠ¥å‘Š[/bold blue]\n")

    metrics_dir = settings.get_absolute_path(settings.metrics.storage_dir)

    if not metrics_dir.exists():
        console.print("[red]âœ—[/red] æš‚æ— æŒ‡æ ‡æ•°æ®")
        raise typer.Exit(1)

    # åŠ è½½æŒ‡æ ‡æ–‡ä»¶
    metric_files = sorted(metrics_dir.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)

    if not metric_files:
        console.print("[red]âœ—[/red] æš‚æ— æŒ‡æ ‡æ•°æ®")
        raise typer.Exit(1)

    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    if last:
        cutoff_time = _parse_time_range(last)
        metric_files = [
            f for f in metric_files if datetime.fromtimestamp(f.stat().st_mtime) >= cutoff_time
        ]

    # æ”¶é›†æ•°æ®
    report_data = []

    for metric_file in metric_files:
        try:
            data = json.loads(metric_file.read_text(encoding="utf-8"))
            report_data.append(data)
        except Exception as e:
            logger.warning(f"è¯»å–æŒ‡æ ‡æ–‡ä»¶å¤±è´¥: {e}")

    # å¯¼å‡º
    output.parent.mkdir(parents=True, exist_ok=True)

    if format == "json":
        output.write_text(json.dumps(report_data, indent=2, ensure_ascii=False), encoding="utf-8")
    elif format == "csv":
        import csv

        with output.open("w", newline="", encoding="utf-8") as f:
            if report_data:
                writer = csv.DictWriter(f, fieldnames=report_data[0].keys())
                writer.writeheader()
                writer.writerows(report_data)

    console.print(f"[green]âœ“[/green] æŠ¥å‘Šå·²ç”Ÿæˆ: {output}")
    console.print(f"  åŒ…å« {len(report_data)} æ¡è®°å½•")


@monitor_app.command("watch")
def watch():
    """å®æ—¶ç›‘æ§å·¥ä½œæµæ‰§è¡Œ.

    Examples:
        temu-auto-publish monitor watch
    """
    console.print("\n[bold blue]ğŸ‘ï¸  å®æ—¶ç›‘æ§[/bold blue]\n")
    console.print("[yellow]âš [/yellow] æ­¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

    # TODO: å®ç°å®æ—¶ç›‘æ§
    # 1. ç›‘å¬æŒ‡æ ‡æ–‡ä»¶å˜åŒ–
    # 2. å®æ—¶æ˜¾ç¤ºæ‰§è¡Œè¿›åº¦
    # 3. å®æ—¶æ›´æ–°ç»Ÿè®¡ä¿¡æ¯


# ========== è¾…åŠ©å‡½æ•° ==========


def _parse_time_range(time_str: str) -> datetime:
    """è§£ææ—¶é—´èŒƒå›´å­—ç¬¦ä¸².

    Args:
        time_str: æ—¶é—´èŒƒå›´(å¦‚: 1h, 24h, 7d)

    Returns:
        æˆªæ­¢æ—¶é—´
    """
    import re

    match = re.match(r"(\d+)([hd])", time_str)
    if not match:
        raise ValueError(f"æ— æ•ˆçš„æ—¶é—´èŒƒå›´: {time_str}")

    value = int(match.group(1))
    unit = match.group(2)

    if unit == "h":
        delta = timedelta(hours=value)
    elif unit == "d":
        delta = timedelta(days=value)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´å•ä½: {unit}")

    return datetime.now() - delta
